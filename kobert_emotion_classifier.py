# -*- coding: utf-8 -*-
"""kobert_emotion_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11xAhcebGaQ-J2-f_-sFPBjfQdbp2Yyk4
"""

# from google.colab import drive
# drive.mount('/content/drive')

# !pip install mxnet
# !pip install gluonnlp pandas tqdm
# !pip install sentencepiece
# !pip install transformers
# !pip install torch

# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'

# %cd /content/drive/MyDrive/day-canvas/deploy

import bert_dataset_tokenizer
from bert_dataset_tokenizer import tokenizer

import bert_classification_model
from bert_classification_model import model

import torch
import numpy as np

from transformers import BertModel
bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)
device = torch.device('cpu')

def predict(model_path, sentence):

    #상의 필요
    #파라미터를 여기에 넣는게 맞는가?
    classification_model = model.BERTClassifier(bertmodel, dr_rate = 0.5, tok = model.tok, vocab = model.vocab, max_len = 128, batch_size = 32).to(device)
    classification_model.load_state_dict(torch.load(model_path, map_location=device))
    classification_model.eval()

    out = classification_model.predict(sentence)
    logits = out.detach().cpu().numpy()

    emotion = []
    if np.argmax(logits) == 0:
        emotion.append("기쁨")
    elif np.argmax(logits) == 1:
        emotion.append("당황")
    elif np.argmax(logits) == 2:
        emotion.append("분노")
    elif np.argmax(logits) == 3:
        emotion.append("불안")
    elif np.argmax(logits) == 4:
        emotion.append("상처")
    elif np.argmax(logits) == 5:
        emotion.append("슬픔")

    return emotion[0]
